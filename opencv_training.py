# -*- coding: utf-8 -*-
"""opencv_training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qJUOxzu7I0muD3SB9vkpSR1skPmh9bY-
"""

import cv2
cv2.__version__

from google.colab import files
uploaded = files.upload()

model_image = 'photo_openCv.jfif'
import cv2
from google.colab.patches import cv2_imshow
img = cv2.imread(model_image)
width = int(img.shape[1] * 50 / 100)
height = int(img.shape[0] * 50 / 100)
dim = (width, height)
image = cv2.resize(img,dim,interpolation = cv2.INTER_AREA)
print(image.shape)
print('Height of an image',int(image.shape[0]),'pixel')
print('Width of an image',int(image.shape[1]),'pixel')

cv2_imshow(image)

#gray converstion
gray_scale = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)
print(gray_scale.shape)
cv2_imshow(gray_scale)
#as we could see this ddoesnt have a channel index

ret ,th = cv2.threshold(image,125,225,cv2.THRESH_BINARY)
cv2_imshow(th)

#changing it to binary image(in general terms black/white) we need to first convert it ot gray otherwise the result wont be required oone
ret2 ,th2 = cv2.threshold(gray_scale,125,225,cv2.THRESH_BINARY)
cv2_imshow(th2)

#changing it to binary image(in general terms white/black) we need to first convert it ot gray otherwise the result wont be required oone
ret1 ,th1 = cv2.threshold(gray_scale,125,225,cv2.THRESH_BINARY_INV)
cv2_imshow(th1)

#how to extract RGB color to color space
import numpy as np 
import cv2
from google.colab import files
uploaded = files.upload()

img = 'photo_openCv.jfif'

image = cv2.imread(img)
width = int(image.shape[1] * 50 / 100)
height = int(image.shape[0] * 50 / 100)
dim = (width, height)
image = cv2.resize(image,dim,interpolation = cv2.INTER_AREA)
B,G,R = cv2.split(image)
zero = np.zeros(image.shape[:2],dtype='uint8')
cv2_imshow(cv2.merge([zero,zero,R]))
cv2_imshow(cv2.merge([zero,G,zero]))
cv2_imshow(cv2.merge([B,zero,zero]))

'''
Function used for live feed in google colab
'''
from IPython.display import HTML, Audio
from google.colab.output import eval_js
from base64 import b64decode
import numpy as np
import io
from PIL import Image

VIDEO_HTML = """
<video autoplay
 width=%d height=%d style='cursor: pointer;'></video>
<script>

var video = document.querySelector('video')

navigator.mediaDevices.getUserMedia({ video: true })
  .then(stream=> video.srcObject = stream)
  
var data = new Promise(resolve=>{
  video.onclick = ()=>{
    var canvas = document.createElement('canvas')
    var [w,h] = [video.offsetWidth, video.offsetHeight]
    canvas.width = w
    canvas.height = h
    canvas.getContext('2d')
          .drawImage(video, 0, 0, w, h)
    video.srcObject.getVideoTracks()[0].stop()
    video.replaceWith(canvas)
    resolve(canvas.toDataURL('image/jpeg', %f))
  }
})
</script>
"""
def take_photo(filename='photo.jpg', quality=0.8, size=(1000,800)):
  display(HTML(VIDEO_HTML % (size[0],size[1],quality)))
  data = eval_js("data")
  binary = b64decode(data.split(',')[1])
  f = io.BytesIO(binary)
  return np.asarray(Image.open(f))

#capturing an image
import cv2
cap =cv2.VideoCapture(0)
while True:
  ret, frame= take_photo()
  cv2_imshow(frame)
  if cv2.waitKey(1)==13:
    break
cap.release()
cv2.destroyAllWindows()

cv2_imshow(image)

img_scaled = cv2.resize(image,None,fx= 0.75,fy=0.75)
cv2_imshow(img_scaled)

img_cubic = cv2.resize(image,None,fx= 0.75,fy=0.75,interpolation= cv2.INTER_CUBIC)
cv2_imshow(img_cubic)

img_area = cv2.resize(image,None,fx= 10,fy=10,interpolation= cv2.INTER_AREA)
cv2_imshow(img_area)

img_nearest = cv2.resize(image,None,fx= 4,fy=4,interpolation= cv2.INTER_NEAREST)
cv2_imshow(img_nearest)

